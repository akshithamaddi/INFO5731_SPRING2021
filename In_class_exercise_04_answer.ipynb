{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_04_answer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshithamaddi/INFO5731_SPRING2021/blob/main/In_class_exercise_04_answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuX00KHNeSpw"
      },
      "source": [
        "# **The fourth in-class-exercise (reference answer)**\n",
        "\n",
        "Provided by psameni"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vTOb03hG1f"
      },
      "source": [
        "# 1. Text Data Preprocessing\n",
        "\n",
        "Here is a [legal case](https://github.com/unt-iialab/INFO5731_Spring2020/blob/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt) we collected from westlaw, please follow the steps we mentioned in lesson 5 to clean the data:\n",
        "\n",
        "\n",
        "\n",
        "## 1.1 Basic feature extraction using text data\n",
        "\n",
        "*   Number of sentences\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average word length\n",
        "*   Number of stopwords\n",
        "*   Number of special characters\n",
        "*   Number of numerics\n",
        "*   Number of uppercase words\n",
        "\n",
        "## 1.2 Basic Text Pre-processing of text data\n",
        "\n",
        "*   Lower casing\n",
        "*   Punctuation removal\n",
        "*   Stopwords removal\n",
        "*   Frequent words removal\n",
        "*   Rare words removal\n",
        "*   Spelling correction\n",
        "*   Tokenization\n",
        "*   Stemming\n",
        "*   Lemmatization\n",
        "\n",
        "## 1.3 Save all the **clean sentences** to a **csv file** (one column, each raw is a sentence) after finishing all the steps above.\n",
        "\n",
        "\n",
        "## 1.4 Advance Text Processing\n",
        "\n",
        "*   Calculate the term frequency of all the terms.\n",
        "*   Print out top 10 1-gram, top 10 2-grams, and top 10 2-grams terms as features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR0L3_CreM_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "8604d065-7270-4811-f1dd-17ea1ac9efd0"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "#reading the .tx file\n",
        "import pandas as pd\n",
        "\n",
        "data_file=\"https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt\"\n",
        "data=pd.read_csv(data_file,error_bad_lines=False,names=['sentence'])\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence\n",
              "0                                     5 Ala. 740\n",
              "1                      Supreme Court of Alabama.\n",
              "2                                          ADAMS\n",
              "3                                             v.\n",
              "4                             TANNER AND HORTON.\n",
              "5                                      June Term\n",
              "6                                       Synopsis\n",
              "7  WRIT of Error to the Circuit Court of Sumter.\n",
              "8                                               \n",
              "9                             West Headnotes (2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2AvEEBUeiZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6f9ea2d-edcd-4d6f-f9b1-664c57f2dd56"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (1) Number of sentences\n",
        "\n",
        "print(\"Number of Sentences :\",len(data['sentence']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Sentences : 148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ITcqxAmfBOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "8714dcbe-b62d-4056-9b78-3cba13a1ca66"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (2) Number of words\n",
        "\n",
        "data['word_count']=data['sentence'].apply(lambda x: len(x.split(\" \")))\n",
        "\n",
        "data[['sentence','word_count']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence  word_count\n",
              "0                                     5 Ala. 740           3\n",
              "1                      Supreme Court of Alabama.           4\n",
              "2                                          ADAMS           1\n",
              "3                                             v.           1\n",
              "4                             TANNER AND HORTON.           3\n",
              "5                                      June Term           2\n",
              "6                                       Synopsis           1\n",
              "7  WRIT of Error to the Circuit Court of Sumter.           9\n",
              "8                                                          1\n",
              "9                             West Headnotes (2)           3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTisz1emfTgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "6f8ecfd0-eb41-4ab9-ebaa-ba1b83d5cca5"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (3) Number of characters\n",
        "\n",
        "data['char_count']=data['sentence'].str.len()\n",
        "\n",
        "data[['sentence','char_count']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence  char_count\n",
              "0                                     5 Ala. 740          10\n",
              "1                      Supreme Court of Alabama.          25\n",
              "2                                          ADAMS           5\n",
              "3                                             v.           2\n",
              "4                             TANNER AND HORTON.          18\n",
              "5                                      June Term           9\n",
              "6                                       Synopsis           8\n",
              "7  WRIT of Error to the Circuit Court of Sumter.          45\n",
              "8                                                          1\n",
              "9                             West Headnotes (2)          18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hntAlr6nfhwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "1dadc098-9c80-4e01-9558-78a35ed7711d"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (4) Number of characters\n",
        "\n",
        "def avg_word(sentence):\n",
        "    words=sentence.split()\n",
        "    if len(words)!=0:\n",
        "     return(sum(len(word) for word in words)/len(words))\n",
        "    else:\n",
        "     return 0\n",
        "\n",
        "data['avg_word_len']=data['sentence'].apply(lambda x: avg_word(x))\n",
        "data[['sentence','avg_word_len']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>avg_word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>5.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "      <td>4.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "      <td>5.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence  avg_word_len\n",
              "0                                     5 Ala. 740      2.666667\n",
              "1                      Supreme Court of Alabama.      5.500000\n",
              "2                                          ADAMS      5.000000\n",
              "3                                             v.      2.000000\n",
              "4                             TANNER AND HORTON.      5.333333\n",
              "5                                      June Term      4.000000\n",
              "6                                       Synopsis      8.000000\n",
              "7  WRIT of Error to the Circuit Court of Sumter.      4.111111\n",
              "8                                                     0.000000\n",
              "9                             West Headnotes (2)      5.333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT4Ei346gNFM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "a68bb02e-b481-4fe4-cdf5-7e63aa080a5a"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (5) Number of stopwords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "\n",
        "data['stop_words_count']=data['sentence'].apply(lambda x: len([y for y in x.split() if y in stop]))\n",
        "data[['sentence','stop_words_count']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>stop_words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence  stop_words_count\n",
              "0                                     5 Ala. 740                 0\n",
              "1                      Supreme Court of Alabama.                 1\n",
              "2                                          ADAMS                 0\n",
              "3                                             v.                 0\n",
              "4                             TANNER AND HORTON.                 0\n",
              "5                                      June Term                 0\n",
              "6                                       Synopsis                 0\n",
              "7  WRIT of Error to the Circuit Court of Sumter.                 4\n",
              "8                                                                0\n",
              "9                             West Headnotes (2)                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU3jNuyRgcIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "e8cb0d1d-c2b5-4995-bd38-65c24490e43d"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (6) Number of special characters\n",
        "\n",
        "data['special_char_count']=data['sentence'].apply(lambda x: len([y for y in x.split() if y.startswith(('#','@'))]))\n",
        "data[['sentence','special_char_count']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>special_char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence  special_char_count\n",
              "0                                     5 Ala. 740                   0\n",
              "1                      Supreme Court of Alabama.                   0\n",
              "2                                          ADAMS                   0\n",
              "3                                             v.                   0\n",
              "4                             TANNER AND HORTON.                   0\n",
              "5                                      June Term                   0\n",
              "6                                       Synopsis                   0\n",
              "7  WRIT of Error to the Circuit Court of Sumter.                   0\n",
              "8                                                                  0\n",
              "9                             West Headnotes (2)                   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2p5XluatCef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "cf1ec922-e3f0-45ed-fda6-b2be920363ad"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (7) number of numerics\n",
        "\n",
        "data['numeric_count']=data['sentence'].apply(lambda x: len([y for y in x.split() if y.isdigit()]))\n",
        "data[['sentence','numeric_count']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>numeric_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence  numeric_count\n",
              "0                                     5 Ala. 740              2\n",
              "1                      Supreme Court of Alabama.              0\n",
              "2                                          ADAMS              0\n",
              "3                                             v.              0\n",
              "4                             TANNER AND HORTON.              0\n",
              "5                                      June Term              0\n",
              "6                                       Synopsis              0\n",
              "7  WRIT of Error to the Circuit Court of Sumter.              0\n",
              "8                                                             0\n",
              "9                             West Headnotes (2)              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM3OIWYEtyrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f2214804-c216-4e00-e96b-61ebb8c72583"
      },
      "source": [
        "# 1.1 Basic feature extraction using text data\n",
        "# (8) Number of uppercase words\n",
        "\n",
        "data['uppercase_words_count']=data['sentence'].apply(lambda x: len([y for y in x.split() if y.isupper()]))\n",
        "data[['sentence','uppercase_words_count']].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>uppercase_words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>June Term</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Synopsis</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>WRIT of Error to the Circuit Court of Sumter.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>West Headnotes (2)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentence  uppercase_words_count\n",
              "0                                     5 Ala. 740                      0\n",
              "1                      Supreme Court of Alabama.                      0\n",
              "2                                          ADAMS                      1\n",
              "3                                             v.                      0\n",
              "4                             TANNER AND HORTON.                      3\n",
              "5                                      June Term                      0\n",
              "6                                       Synopsis                      0\n",
              "7  WRIT of Error to the Circuit Court of Sumter.                      1\n",
              "8                                                                     0\n",
              "9                             West Headnotes (2)                      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXTXURqoxMeJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ec5371eb-66f4-4aec-8c10-f21590f1f348"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (1) Lower casing\n",
        "\n",
        "data['sentence']=data['sentence'].str.lower()\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                       5 ala. 740\n",
              "1                        supreme court of alabama.\n",
              "2                                            adams\n",
              "3                                               v.\n",
              "4                               tanner and horton.\n",
              "5                                        june term\n",
              "6                                         synopsis\n",
              "7    writ of error to the circuit court of sumter.\n",
              "8                                                 \n",
              "9                               west headnotes (2)\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04_6O0HKxtQF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e0ecda72-1f48-4cf5-f83f-f4bc645bce3c"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (2) Punctuation removal\n",
        "\n",
        "import string\n",
        "data['sentence']=data['sentence'].str.replace('[{}]'.format(string.punctuation), '')\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                       5 ala 740\n",
              "1                        supreme court of alabama\n",
              "2                                           adams\n",
              "3                                               v\n",
              "4                               tanner and horton\n",
              "5                                       june term\n",
              "6                                        synopsis\n",
              "7    writ of error to the circuit court of sumter\n",
              "8                                                \n",
              "9                                west headnotes 2\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70iQwI8Gx-l8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7fd97d82-964a-4da0-a8bf-ac5943e94675"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (3) Stopwords removal\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "\n",
        "data['sentence']=data['sentence'].apply(lambda x:\" \".join(x for x in x.split() if x not in stop))\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  740\n",
              "1      supreme alabama\n",
              "2                adams\n",
              "3                     \n",
              "4        tanner horton\n",
              "5                 june\n",
              "6             synopsis\n",
              "7    writ error sumter\n",
              "8                     \n",
              "9       west headnotes\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A0PMkVwyJL1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eafa2ba4-62f0-4aea-e945-c6206c8bb2d4"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (4) Frequent words removal\n",
        "\n",
        "freq=pd.Series(' '.join(data['sentence']).split()).value_counts()[:10]\n",
        "freq=list(freq.index)\n",
        "\n",
        "data['sentence']=data['sentence'].apply(lambda x:\" \".join(x for x in x.split() if x not in freq))\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  740\n",
              "1      supreme alabama\n",
              "2                adams\n",
              "3                     \n",
              "4        tanner horton\n",
              "5                 june\n",
              "6             synopsis\n",
              "7    writ error sumter\n",
              "8                     \n",
              "9       west headnotes\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I480t9LygKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "411bb703-fbad-4fc4-d98c-f283ca9bed34"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (5) Rare words removal\n",
        "\n",
        "rare=pd.Series(' '.join(data['sentence']).split()).value_counts()[-10:]\n",
        "\n",
        "rare=list(rare.index)\n",
        "data['sentence']=data['sentence'].apply(lambda x:\" \".join(x for x in x.split() if x not in rare))\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  740\n",
              "1      supreme alabama\n",
              "2                adams\n",
              "3                     \n",
              "4        tanner horton\n",
              "5                 june\n",
              "6             synopsis\n",
              "7    writ error sumter\n",
              "8                     \n",
              "9       west headnotes\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGgdKSyW3ZQh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f3828d1f-aca5-4297-8080-48fbecf45d37"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (6) Spelling correction\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "data['sentence']=data['sentence'].apply(lambda x: str(TextBlob(x).correct()))\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  740\n",
              "1      supreme alabama\n",
              "2                adams\n",
              "3                     \n",
              "4        manner norton\n",
              "5                 june\n",
              "6              sycosis\n",
              "7    writ error sumter\n",
              "8                     \n",
              "9       west headnotes\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQiNliPA3rcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ccd69cca-2706-4d99-8d00-0a0db09f48a6"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (7) Stemming\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "\n",
        "data['sentence']=data['sentence'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  740\n",
              "1       suprem alabama\n",
              "2                 adam\n",
              "3                     \n",
              "4        manner norton\n",
              "5                 june\n",
              "6               sycosi\n",
              "7    writ error sumter\n",
              "8                     \n",
              "9         west headnot\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TK9WfDW4Jov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "99bb2310-b03e-4386-b89f-eff6ff64367b"
      },
      "source": [
        "# 1.2 Basic Text Pre-processing of text data\n",
        "# (8) Lemmatization\n",
        "\n",
        "from textblob import Word\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "data['sentence']=data['sentence'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  740\n",
              "1       suprem alabama\n",
              "2                 adam\n",
              "3                     \n",
              "4        manner norton\n",
              "5                 june\n",
              "6               sycosi\n",
              "7    writ error sumter\n",
              "8                     \n",
              "9         west headnot\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN3NiPyL4h5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d92ce39b-862d-42f1-833c-2ba099024bb1"
      },
      "source": [
        "# Dropping empty rows\n",
        "sentence=data[\"sentence\"] != \"\"\n",
        "data=data[sentence]\n",
        "data=data.reset_index(inplace=False)\n",
        "data['sentence'].head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  740\n",
              "1       suprem alabama\n",
              "2                 adam\n",
              "3        manner norton\n",
              "4                 june\n",
              "5               sycosi\n",
              "6    writ error sumter\n",
              "7         west headnot\n",
              "8                    1\n",
              "9      chattel mortgag\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veVBuy2B4yNg"
      },
      "source": [
        "# 1.3 Saving the formatted sentences to \"clean.txt\"\n",
        "\n",
        "data['sentence'].to_csv(\"clean.txt\",header=False,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvfFzbOq49mo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "19b8284e-2db1-4cde-8cc4-a35b9ffc2192"
      },
      "source": [
        "# 1.4 Advance Text Processing\n",
        "# (1) Calculate the term frequency of all the terms\n",
        "\n",
        "tf=(data['sentence']).apply(lambda x: pd.value_counts(x.split(' '))).sum(axis=0).reset_index()\n",
        "tf.columns=['word','Term Frequency']\n",
        "tf.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>Term Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>740</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>suprem</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>alabama</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adam</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>norton</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>manner</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>june</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sycosi</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sumter</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>writ</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      word  Term Frequency\n",
              "0      740             2.0\n",
              "1   suprem             1.0\n",
              "2  alabama             1.0\n",
              "3     adam             1.0\n",
              "4   norton             1.0\n",
              "5   manner             2.0\n",
              "6     june             1.0\n",
              "7   sycosi             1.0\n",
              "8   sumter             1.0\n",
              "9     writ             2.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywfVK4x28R-y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6b952f76-a04d-4992-901f-7daad28c8d7c"
      },
      "source": [
        "# 1.4 Advance Text Processing\n",
        "# (2) Print out top 10 1-gram, top 10 2-grams, and top 10 2-grams terms as features\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "data_file=\"clean.txt\"\n",
        "data=pd.read_csv(data_file,error_bad_lines=False,names=['sentence'])\n",
        "vectorizer = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english', ngram_range = (1,3))\n",
        "X = vectorizer.fit_transform(data['sentence'])\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['108', '145', '182', '1852', '1857', '1871', '1872', '1876', '1880', '1887', '1936', '2019', '2019 thomson', '2019 thomson renter', '21', '21 333', '256', '266', '31', '31 526', '329', '333', '362', '39', '45', '45 329', '464', '47', '47 362', '526', '65', '65 256', '740', '913', 'act', 'act consid', 'act consid act', 'act subject', 'act subject polici', 'adam', 'admiss', 'admiss contradict', 'admit', 'admit contract', 'admit contract defend', 'alabama', 'ampl', 'assert', 'attach', 'attorney', 'attorney law', 'attorney law firm', 'austin', 'austin lawyer', 'autauga', 'autauga moor', 'author', 'bale', 'bale cotton', 'bale cotton etowah', 'banish', 'banish wage', 'banish wage exempt', 'bite', 'bite refer', 'bring', 'bring question', 'cal', 'cal 145', 'case', 'case cite', 'case cite headnot', 'charg', 'charg juri', 'chattel', 'chattel mortgag', 'cite', 'cite headnot', 'citi', 'citi montgomeri', 'citi montgomeri john', 'claim', 'claim govern', 'claim govern work', 'claimant', 'claimant assert', 'claimant levi', 'claimant levi taken', 'coat', 'confirm', 'confirm correct', 'confirm correct view', 'consid', 'consid act', 'consid act subject', 'consid claimant', 'consid claimant assert', 'contract', 'contract defend', 'contract pas', 'contract pas vest', 'contract sale', 'contradict', 'convers', 'convers bale', 'convers bale cotton', 'convers cotton', 'convers cotton citi', 'correct', 'correct view', 'correct view necessari', 'cotton', 'cotton citi', 'cotton citi montgomeri', 'cotton etowah', 'cotton etowah wm', 'cotton harbour', 'cotton harbour hale', 'cow', 'cow 39', 'crop', 'crop subject', 'crop subject levi', 'cunningham', 'date', 'defend', 'depth', 'destroy', 'dewey', 'dewey woman', 'dissent', 'dissent opinion', 'doughi', 'edward', 'edward thompson', 'end', 'enquiri', 'enter', 'enter enquiri', 'error', 'error autauga', 'error autauga moor', 'error sumter', 'error tuskaloosa', 'etowah', 'etowah wm', 'etowah wm whitlow', 'evan', 'evan later', 'evid', 'evid admiss', 'evid admiss contradict', 'exempt', 'exempt citi', 'exempt citi montgomeri', 'exist', 'exist subject', 'exist subject matter', 'exist subjectmatt', 'exist subjectmatt mortgag', 'farm', 'farm year', 'file', 'file situat', 'firm', 'gener', 'german', 'gibb', 'gibb manner', 'govern', 'govern work', 'grover', 'grover convers', 'grover convers bale', 'grover convers cotton', 'grow', 'grow crop', 'grow crop subject', 'grow exist', 'grow exist subject', 'grow exist subjectmatt', 'hale', 'harbour', 'harbour hale', 'hayfield', 'headnot', 'histori', 'histori result', 'histori result situat', 'hooker', 'hooker jones', 'jan', 'jan 1871', 'jan 1872', 'john', 'john 108', 'john cunningham', 'jones', 'judgment', 'juli', 'juli 1857', 'june', 'juri', 'later', 'law', 'law firm', 'law suppos', 'law suppos contract', 'lawyer', 'let', 'let farm', 'let farm year', 'levi', 'levi plant', 'levi seizur', 'levi seizur attach', 'levi taken', 'levi taken posse', 'line', 'line destroy', 'line prioriti', 'manner', 'manner norton', 'matter', 'matter sale', 'mckenzi', 'mckenzi ampl', 'montgomeri', 'montgomeri john', 'montgomeri john cunningham', 'moor', 'mormon', 'mortgag', 'mortgag contract', 'mortgag contract pas', 'murphi', 'necessari', 'neg', 'neg treatment', 'neg treatment result', 'norton', 'nov', 'nov 1880', 'novemb', 'number', 'opinion', 'page', 'page number', 'pas', 'pas vest', 'pas vest posse', 'person', 'person hayfield', 'plant', 'polici', 'polici state', 'port', 'port 182', 'posse', 'present', 'present question', 'prioriti', 'properti', 'properti cotton', 'properti cotton harbour', 'properti statut', 'properti statut novemb', 'question', 'quot', 'refer', 'refer titl', 'remedi', 'renter', 'renter claim', 'renter claim govern', 'result', 'result said', 'result situat', 'run', 'run 1852', 'said', 'sale', 'seizur', 'seizur attach', 'shall', 'shall enter', 'shall enter enquiri', 'situat', 'smith', 'st1821', 'state', 'statut', 'statut novemb', 'statut present', 'statut present question', 'stewart', 'stewart doughi', 'subject', 'subject levi', 'subject levi seizur', 'subject matter', 'subject matter sale', 'subject polici', 'subject polici state', 'subjectmatt', 'subjectmatt mortgag', 'subjectmatt mortgag contract', 'sumter', 'suppos', 'suppos contract', 'suppos contract sale', 'suprem', 'suprem alabama', 'sycosi', 'tabl', 'tabl author', 'taken', 'taken posse', 'thompson', 'thomson', 'thomson renter', 'thomson renter claim', 'titl', 'treatment', 'treatment result', 'treatment result situat', 'tree', 'tree coat', 'trial', 'trial properti', 'trial properti cotton', 'trial properti statut', 'tuskaloosa', 'type', 'vest', 'vest posse', 'view', 'view necessari', 'wage', 'wage exempt', 'wage exempt citi', 'west', 'west headnot', 'whitlow', 'wm', 'wm whitlow', 'woman', 'work', 'writ', 'writ error', 'writ error sumter', 'writ error tuskaloosa', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBiC4E_kefvV"
      },
      "source": [
        "# 2. Python Regular Expression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1QJ-UwCenvN"
      },
      "source": [
        "## 2.1 Write a Python program to remove leading zeros from an IP address. \n",
        "\n",
        "ip = \"260.08.094.109\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSv6fVhOfFmv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ed519b6-4ba0-49cb-8010-136823da926e"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "import re\n",
        "ip=\"260.08.094.109\"\n",
        "str = re.sub('\\.[0]*', '.', ip)\n",
        "print(str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "260.8.94.109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXRjaHzrfKAy"
      },
      "source": [
        "## 2.2 Write a Python Program to extract all the years from the following sentence.\n",
        "\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdJpDx9gjbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55493a93-e3dc-4740-83f6-010b7f3b17a0"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "import re\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump\"\n",
        "years = re.findall(r'2\\d\\d\\d', sentence)\n",
        "print(years)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2010', '2010', '2019']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}